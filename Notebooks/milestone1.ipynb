{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":128431,"databundleVersionId":15477148,"sourceType":"competition"}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Milestone 1\n\nThis milestone focuses on understanding the dataset and establishing a baseline performance through **exploratory data analysis (EDA)** and simple **heuristic-based methods** using `librosa`.\n\n---\n\n## Suggested Readings\n- [Hugging Face Audio Course](https://huggingface.co/learn/audio-course/en/chapter0/introduction)\n- [Librosa Documentation](https://librosa.org/doc/main/core.html#audio-loading)\n\n---\n\n## Instructions\nUse this notebook to answer **all Milestone-1 questions**.\n\n---\n\n## Resources\n- Notebook Link:  \n  https://colab.research.google.com/drive/1m6UczhxQIke_raWSqukSWuiKbIVt7MMb?usp=sharing  \n\n- Competition Link:  \n  https://www.kaggle.com/competitions/jan-2026-dl-gen-ai-project/\n","metadata":{"id":"2OhS0NNSgfjf"}},{"cell_type":"code","source":"import os\nimport glob\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport librosa\nimport librosa.display\nimport matplotlib.pyplot as plt\nimport random\nimport torch\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"id":"P98avCy_pVzP","execution":{"iopub.status.busy":"2026-02-18T18:07:47.082266Z","iopub.execute_input":"2026-02-18T18:07:47.082636Z","iopub.status.idle":"2026-02-18T18:07:47.088377Z","shell.execute_reply.started":"2026-02-18T18:07:47.082607Z","shell.execute_reply":"2026-02-18T18:07:47.087428Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"#----------------------------- DON'T CHANGE THIS --------------------------\nDATA_SEED = 67\nTRAINING_SEED = 1234\nSR = 22050\nDURATION = 5.0\nN_FFT = 2048\nHOP_LENGTH = 512\nN_MELS = 128\nTOP_DB=20\nTARGET_SNR_DB = 10\n\nrandom.seed(DATA_SEED)\nnp.random.seed(DATA_SEED)\ntorch.manual_seed(DATA_SEED)\ntorch.cuda.manual_seed(DATA_SEED)","metadata":{"trusted":true,"id":"FJDKs-0cpVzR","execution":{"iopub.status.busy":"2026-02-18T18:07:47.090178Z","iopub.execute_input":"2026-02-18T18:07:47.090614Z","iopub.status.idle":"2026-02-18T18:07:47.116651Z","shell.execute_reply.started":"2026-02-18T18:07:47.090584Z","shell.execute_reply":"2026-02-18T18:07:47.115463Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# CONFIGURATION\nDATA_ROOT = '/kaggle/input/jan-2026-dl-gen-ai-project/messy_mashup/genres_stems'\nGENRES = sorted([g for g in os.listdir(DATA_ROOT) \n                 if os.path.isdir(os.path.join(DATA_ROOT, g))]) # Make the list of all genres available (alphabetical order)\nSTEM_KEYS = ['drums', 'vocals', 'bass', 'other']\nSTEMS = {\n    'drums.wav': 'drums',\n    'vocals.wav': 'vocals',\n    'bass.wav': 'bass',\n    'other.wav': 'other'\n}\nGENRE_TO_TEST = 'rock'\n# SONG_INDEX = #Enter index as per Q10.","metadata":{"trusted":true,"id":"3bcdenPtpVzS","execution":{"iopub.status.busy":"2026-02-18T18:07:47.117987Z","iopub.execute_input":"2026-02-18T18:07:47.118343Z","iopub.status.idle":"2026-02-18T18:07:47.146570Z","shell.execute_reply.started":"2026-02-18T18:07:47.118279Z","shell.execute_reply":"2026-02-18T18:07:47.145335Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def build_dataset(root_dir, val_split=0.17, seed=42):\n\n    train_dataset = {g: {k: [] for k in STEM_KEYS} for g in GENRES}\n    val_dataset   = {g: {k: [] for k in STEM_KEYS} for g in GENRES}\n\n    rng = random.Random(seed)\n\n    corrupted_count = 0\n    less_5_0491MB = 0\n    greater_5_0493MB = 0\n\n    for genre in GENRES:\n        genre_path = os.path.join(root_dir, genre)\n        songs = sorted(os.listdir(genre_path))\n\n        valid_songs = []\n\n        for song in songs:\n            song_path = os.path.join(genre_path, song)\n            stem_files = []\n\n            for stem_file in STEMS:\n                fpath = os.path.join(song_path, stem_file)\n                if not os.path.exists(fpath):\n                    break\n                size = os.path.getsize(fpath)\n\n                # corruption check (< 4 KB)\n                if size < 4 * 1024:\n                    corrupted_count += 1\n\n                # size comparisons\n                if size < 5.0491 * 1024 * 1024:\n                    less_5_0491MB += 1\n\n                if size > 5.0493 * 1024 * 1024:\n                    greater_5_0493MB += 1\n\n                stem_files.append(fpath)\n\n            if len(stem_files) == 4:\n                valid_songs.append(song_path)\n\n        rng.shuffle(valid_songs)\n\n        split_idx = int(len(valid_songs) * (1 - val_split))\n        train_songs = valid_songs[:split_idx]\n        val_songs   = valid_songs[split_idx:]\n\n        for s in train_songs:\n            for stem_file in STEMS:\n                train_dataset[genre][STEMS[stem_file]].append(\n                    os.path.join(s, stem_file)\n                )\n\n        for s in val_songs:\n            for stem_file in STEMS:\n                val_dataset[genre][STEMS[stem_file]].append(\n                    os.path.join(s, stem_file)\n                )\n\n    print(\"\\n--- Q1 ---\")\n    print(\"Corrupted + (<5.0491MB):\", corrupted_count + less_5_0491MB)\n\n    print(\"\\n--- Q2 ---\")\n    print(\"Absolute difference:\",\n          abs(greater_5_0493MB - less_5_0491MB))\n\n    print(\"\\n--- Q3 ---\")\n    reggae_train_drums = len(train_dataset['reggae']['drums'])\n    country_val_vocals = len(val_dataset['country']['vocals'])\n    print(\"Absolute difference:\",\n          abs(reggae_train_drums - country_val_vocals))\n\n    return train_dataset, val_dataset\n\n\ntr, val = build_dataset(DATA_ROOT)\n","metadata":{"trusted":true,"id":"SD382v9NpVzS","execution":{"iopub.status.busy":"2026-02-18T18:07:47.147877Z","iopub.execute_input":"2026-02-18T18:07:47.148170Z","iopub.status.idle":"2026-02-18T18:07:53.018739Z","shell.execute_reply.started":"2026-02-18T18:07:47.148138Z","shell.execute_reply":"2026-02-18T18:07:53.017641Z"}},"outputs":[{"name":"stdout","text":"\n--- Q1 ---\nCorrupted + (<5.0491MB): 1256\n\n--- Q2 ---\nAbsolute difference: 1072\n\n--- Q3 ---\nAbsolute difference: 66\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"def find_long_silences(dataset_dict, sr=SR, threshold_sec=DURATION, top_db=TOP_DB):\n\n    records = []\n\n    for genre in dataset_dict:\n        for stem in dataset_dict[genre]:\n            for file_path in tqdm(dataset_dict[genre][stem], leave=False):\n\n                y, _ = librosa.load(file_path, sr=sr)\n                total_duration = len(y) / sr\n\n                intervals = librosa.effects.split(y, top_db=top_db)\n\n                silence_type = []\n                max_silence = 0\n\n                if len(intervals) == 0:\n                    max_silence = total_duration\n                    silence_type.append(\"Full\")\n\n                else:\n                    if intervals[0][0] > 0:\n                        start_silence = intervals[0][0] / sr\n                        max_silence = max(max_silence, start_silence)\n                        silence_type.append(\"Start\")\n\n                    if intervals[-1][1] < len(y):\n                        end_silence = (len(y) - intervals[-1][1]) / sr\n                        max_silence = max(max_silence, end_silence)\n                        silence_type.append(\"End\")\n\n                    for i in range(len(intervals)-1):\n                        gap = (intervals[i+1][0] - intervals[i][1]) / sr\n                        if gap > 0:\n                            max_silence = max(max_silence, gap)\n                            silence_type.append(\"Middle\")\n\n                if max_silence >= threshold_sec:\n                    records.append({\n                        \"Genre\": genre,\n                        \"Stem\": stem,\n                        \"Duration\": round(total_duration,2),\n                        \"Max_Silence_Sec\": round(max_silence,2),\n                        \"Silence_Location\": \", \".join(silence_type),\n                        \"File_Path\": file_path\n                    })\n\n    df = pd.DataFrame(records)\n    return df\n\n\ndf_silence = find_long_silences(tr)\n\nprint(\"\\n--- Q4 ---\")\nprint(\"Total files silence >=5:\", len(df_silence))\n\nprint(\"\\n--- Q5 ---\")\nprint(\"Vocals silence >=5:\",\n      len(df_silence[df_silence['Stem']=='vocals']))\n\nprint(\"\\n--- Q6 ---\")\nprint(\"Average silence vocals:\",\n      df_silence[df_silence['Stem']=='vocals']['Max_Silence_Sec'].mean())\n\nprint(\"\\n--- Q7 ---\")\nprint(\"Jazz drums silence >=5:\",\n      len(df_silence[(df_silence['Genre']=='jazz') &\n                     (df_silence['Stem']=='drums')]))\n\nprint(\"\\n--- Q8 ---\")\nprint(\"Jazz drums middle only:\",\n      len(df_silence[(df_silence['Genre']=='jazz') &\n                     (df_silence['Stem']=='drums') &\n                     (df_silence['Silence_Location']=='Middle')]))\n\nprint(\"\\n--- Q9 ---\")\nprint(\"Jazz drums silence >=10:\",\n      len(df_silence[(df_silence['Genre']=='jazz') &\n                     (df_silence['Stem']=='drums') &\n                     (df_silence['Max_Silence_Sec']>=10)]))\n\n# ----------------------------------------\n# Q10â€“Q12 MIX SAMPLE\n# ----------------------------------------\nrock_songs = sorted(os.listdir(os.path.join(DATA_ROOT,'rock')))\nfirst_song = rock_songs[0]\n","metadata":{"trusted":true,"id":"QEDE0cXmpVzS","execution":{"iopub.status.busy":"2026-02-18T18:07:53.021139Z","iopub.execute_input":"2026-02-18T18:07:53.021512Z","iopub.status.idle":"2026-02-18T18:15:08.681525Z","shell.execute_reply.started":"2026-02-18T18:07:53.021482Z","shell.execute_reply":"2026-02-18T18:15:08.679384Z"}},"outputs":[{"name":"stderr","text":"                                               ","output_type":"stream"},{"name":"stdout","text":"\n--- Q4 ---\nTotal files silence >=5: 680\n\n--- Q5 ---\nVocals silence >=5: 304\n\n--- Q6 ---\nAverage silence vocals: 12.590789473684211\n\n--- Q7 ---\nJazz drums silence >=5: 24\n\n--- Q8 ---\nJazz drums middle only: 0\n\n--- Q9 ---\nJazz drums silence >=10: 7\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"stems_audio = []\ntry:\n    for stem_file in STEMS:\n        path = os.path.join(DATA_ROOT,'rock',first_song,stem_file)\n        y,_ = librosa.load(path, sr=SR, duration=5.0)\n        stems_audio.append(y)\n\n    print(\"Audio loaded successfully.\")\nexcept NameError:\n    print(\"ERROR: 'tr' dictionary not found. Please run build_dataset() first.\")\nexcept IndexError:\n    print(f\"ERROR: Song index {SONG_INDEX} out of range for genre {GENRE_TO_TEST}.\")\nexcept Exception as e:\n    print(f\"ERROR: {e}\")","metadata":{"trusted":true,"id":"yQ5TsIJupVzT","execution":{"iopub.status.busy":"2026-02-18T18:15:08.684672Z","iopub.execute_input":"2026-02-18T18:15:08.686409Z","iopub.status.idle":"2026-02-18T18:15:08.797045Z","shell.execute_reply.started":"2026-02-18T18:15:08.686364Z","shell.execute_reply":"2026-02-18T18:15:08.795808Z"}},"outputs":[{"name":"stdout","text":"Audio loaded successfully.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# ------------------- write your code here -------------------------------\n# Stack them into a numpy array (Shape: 4 x Samples)\nstems_stack = np.vstack(stems_audio)\n\n# Mix the stems by summing them element-wise\nmix_raw = np.sum(stems_stack, axis=0)\n\n# Calculate RMS Amplitude MANUALLY\nrms_val = np.sqrt(np.mean(mix_raw**2))\n\n#Peak Normalization\nmax_val = np.max(np.abs(mix_raw))\n\nif max_val > 0:\n    mix_norm = mix_raw / max_val\nelse:\n    mix_norm = mix_raw\n\n# VALIDATION\nassert np.isclose(np.max(np.abs(mix_norm)), 1.0), \"Normalization failed.\"\n#------------------------------------------------------------------------\nprint(\"\\n--- Q10 ---\")\nprint(\"Mix length:\", len(mix_raw))\n\nprint(\"\\n--- Q11 ---\")\nprint(\"RMS:\", round(rms_val,2))\n\nprint(\"\\n--- Q12 ---\")\nprint(\"Max peak before norm:\", max_val)","metadata":{"trusted":true,"id":"7SuonlR-pVzT","execution":{"iopub.status.busy":"2026-02-18T18:15:08.798697Z","iopub.execute_input":"2026-02-18T18:15:08.799115Z","iopub.status.idle":"2026-02-18T18:15:08.811326Z","shell.execute_reply.started":"2026-02-18T18:15:08.799063Z","shell.execute_reply":"2026-02-18T18:15:08.810402Z"}},"outputs":[{"name":"stdout","text":"\n--- Q10 ---\nMix length: 110250\n\n--- Q11 ---\nRMS: 0.2\n\n--- Q12 ---\nMax peak before norm: 0.96006984\n","output_type":"stream"}],"execution_count":10}]}